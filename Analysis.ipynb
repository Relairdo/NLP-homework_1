{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import argparse\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import time\r\n",
    "import os\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from scipy.sparse.construct import vstack\r\n",
    "from features import get_dataframe, update_text, update_ngrams, update_lexicon, upadate_linguistic, update_user, get_features, get_lable\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import classification_report, accuracy_score, balanced_accuracy_score, plot_confusion_matrix\r\n",
    "from sklearn.model_selection import cross_val_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "parser = argparse.ArgumentParser()\r\n",
    "parser.add_argument('--train', dest='train', required=False, default='data/train.jsonl',\r\n",
    "                    help='Full path to the training file')\r\n",
    "parser.add_argument('--test', dest='test', required=False, default='data/val.jsonl',\r\n",
    "                    help='Full path to the evaluation file')\r\n",
    "parser.add_argument('--user_data', dest='user_data', required=False, default='data/users.json',\r\n",
    "                    help='Full path to the user data file')\r\n",
    "parser.add_argument('--model', dest='model', required=False, default='Ngram+Lex+Ling+User',\r\n",
    "                    choices=[\"Ngram\", \"Ngram+Lex\", \"Ngram+Lex+Ling\", \"Ngram+Lex+Ling+User\"],\r\n",
    "                    help='The name of the model to train and evaluate.')\r\n",
    "parser.add_argument('--lexicon_path', dest='lexicon_path', required=False, default='lexica/',\r\n",
    "                    help='The full path to the directory containing the lexica.'\r\n",
    "                            ' The last folder of this path should be \"lexica\".')\r\n",
    "parser.add_argument('--outfile', dest='outfile', required=False, default='out.txt',\r\n",
    "                    help='Full path to the file we will write the model predictions')\r\n",
    "                    \r\n",
    "args = parser.parse_args(\"\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train_loc = os.path.join('df_train.pkl')\r\n",
    "df_test_loc = os.path.join('df_test.pkl')\r\n",
    "\r\n",
    "\r\n",
    "if os.path.isfile(df_train_loc) and os.path.isfile(df_test_loc):\r\n",
    "    df_train = pd.read_pickle(df_train_loc)\r\n",
    "    df_test = pd.read_pickle(df_test_loc)\r\n",
    "\r\n",
    "else:\r\n",
    "\r\n",
    "    start = time.time()\r\n",
    "\r\n",
    "    df_train, df_test = get_dataframe(args.train, args.test)\r\n",
    "    update_text(df_train, df_test)\r\n",
    "    update_ngrams(df_train, df_test, feature_number=25000)\r\n",
    "    update_lexicon(df_train, df_test, args.lexicon_path)\r\n",
    "    upadate_linguistic(df_train, df_test)\r\n",
    "    update_user(df_train, df_test, args.user_data)\r\n",
    "\r\n",
    "    end = time.time()\r\n",
    "    print(\"Data Preprocessiong Cost:\", round(end - start),'s.')\r\n",
    "\r\n",
    "    df_train.to_pickle(df_train_loc)\r\n",
    "    df_test.to_pickle(df_test_loc)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train_r = df_train[df_train['category']=='Religion']\r\n",
    "df_train_nr = df_train[df_train['category']!='Religion']\r\n",
    "df_test_r = df_test[df_test['category']=='Religion']\r\n",
    "df_test_nr = df_test[df_test['category']!='Religion']\r\n",
    "print(len(df_train_r)+len(df_test_r), len(df_train_nr)+len(df_test_nr))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "463 1528\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import itertools\r\n",
    "def get_all_combinations(l : list, choose2=False) -> list:\r\n",
    "    ll = []\r\n",
    "    for L in range(0, len(l)+1):\r\n",
    "        for subset in itertools.combinations(l, L):\r\n",
    "            if choose2:\r\n",
    "                if len(list(subset)) == 2:\r\n",
    "                    ll.append(list(subset))\r\n",
    "            else:\r\n",
    "                ll.append(list(subset))\r\n",
    "    return ll\r\n",
    "\r\n",
    "ling_feature_list = ['Length', 'R2O', 'Personal_pronouns', 'Modals', 'Links', 'Questions']\r\n",
    "user_feature_list = ['education','ethnicity', 'gender', 'income', 'joined', 'party', 'political_ideology', 'relationship', 'religious_ideology']\r\n",
    "lexicons_list = [\"CL\", \"NVL\"]\r\n",
    "all_feature_list = list(lexicons_list+ling_feature_list+user_feature_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "column_names = [\"target_feature\",\"mean_score\", \"scores\"]\r\n",
    "df_record = pd.DataFrame(columns = column_names)\r\n",
    "\r\n",
    "\r\n",
    "for feature in all_feature_list:\r\n",
    "\r\n",
    "    ling_feature_list = ['Length', 'R2O', 'Personal_pronouns', 'Modals', 'Links', 'Questions']\r\n",
    "    user_feature_list = ['education','ethnicity', 'gender', 'income', 'joined', 'party', 'political_ideology', 'relationship', 'religious_ideology']\r\n",
    "    lexicons_list = [\"CL\", \"NVL\"]\r\n",
    "        \r\n",
    "    if feature in ling_feature_list:\r\n",
    "        ling_feature_list.remove(feature)\r\n",
    "    if feature in user_feature_list:\r\n",
    "        user_feature_list.remove(feature)\r\n",
    "    if feature in lexicons_list:\r\n",
    "        lexicons_list.remove(feature)\r\n",
    "\r\n",
    "    x_train, x_test = get_features(df_train, df_test, model = args.model,lex_list=lexicons_list, ling_list=ling_feature_list, user_list=user_feature_list)\r\n",
    "    y_train, y_test = get_lable(df_train, df_test)\r\n",
    "    # print('total features:', x_train.shape[1])\r\n",
    "\r\n",
    "    x = vstack([x_train,x_test])\r\n",
    "    y = y_train + y_test\r\n",
    "    clf = LogisticRegression(solver='liblinear')\r\n",
    "    start = time.time()\r\n",
    "    scores = cross_val_score(clf, x, y, cv=5 ,scoring='accuracy')\r\n",
    "    end = time.time()\r\n",
    "    # print(\"Training Model Cost:\", round(end - start),'s.')\r\n",
    "    # print(scores)\r\n",
    "    mean_score = np.mean(scores)\r\n",
    "    # print(\"CV mean:\", mean_score)\r\n",
    "\r\n",
    "    record = {\"target_feature\":feature, \"mean_score\":mean_score, \"scores\":scores}\r\n",
    "    df_record = df_record.append(record,ignore_index=True)\r\n",
    "\r\n",
    "\r\n",
    "df_record.to_csv(os.path.join('Ablation.csv'))\r\n",
    "print(\"Wrote record to df_record.csv.\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Lexicon used: NRC-VAD \n",
      "Linguistic features: Length R2O Personal_pronouns Modals Links Questions \n",
      "User features: education ethnicity gender income joined party political_ideology relationship religious_ideology \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\fff32\\miniconda3\\envs\\NLP-hw1\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Lexicon used: Connotation \n",
      "Linguistic features: Length R2O Personal_pronouns Modals Links Questions \n",
      "User features: education ethnicity gender income joined party political_ideology relationship religious_ideology \n",
      "Lexicon used: Connotation NRC-VAD \n",
      "Linguistic features: R2O Personal_pronouns Modals Links Questions \n",
      "User features: education ethnicity gender income joined party political_ideology relationship religious_ideology \n",
      "Lexicon used: Connotation NRC-VAD \n",
      "Linguistic features: Length Personal_pronouns Modals Links Questions \n",
      "User features: education ethnicity gender income joined party political_ideology relationship religious_ideology \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\fff32\\miniconda3\\envs\\NLP-hw1\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Lexicon used: Connotation NRC-VAD \n",
      "Linguistic features: Length R2O Modals Links Questions \n",
      "User features: education ethnicity gender income joined party political_ideology relationship religious_ideology \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\fff32\\miniconda3\\envs\\NLP-hw1\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Lexicon used: Connotation NRC-VAD \n",
      "Linguistic features: Length R2O Personal_pronouns Links Questions \n",
      "User features: education ethnicity gender income joined party political_ideology relationship religious_ideology \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\fff32\\miniconda3\\envs\\NLP-hw1\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Lexicon used: Connotation NRC-VAD \n",
      "Linguistic features: Length R2O Personal_pronouns Modals Questions \n",
      "User features: education ethnicity gender income joined party political_ideology relationship religious_ideology \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\fff32\\miniconda3\\envs\\NLP-hw1\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\fff32\\miniconda3\\envs\\NLP-hw1\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Lexicon used: Connotation NRC-VAD \n",
      "Linguistic features: Length R2O Personal_pronouns Modals Links \n",
      "User features: education ethnicity gender income joined party political_ideology relationship religious_ideology \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\fff32\\miniconda3\\envs\\NLP-hw1\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('NLP-hw1': conda)"
  },
  "interpreter": {
   "hash": "71e2e5b76bcbb14e570851f735b138803c85a1bc8fc18edcb67e91ecf28dd39d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}